{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS tagging\n",
    "\n",
    "In this notebook, we explore what can be done with the POS tagging of the social media posts of the State Election Officials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words that can be captured:\n",
    "\n",
    "- ADJ: Adjective (e.g., \"happy\", \"large\")\n",
    "- ADP: Adposition (preposition or postposition, e.g., \"in\", \"on\")\n",
    "- ADV: Adverb (e.g., \"quickly\", \"very\")\n",
    "- AUX: Auxiliary verb (e.g., \"is\", \"will\", \"can\")\n",
    "- CONJ: Coordinating conjunction (e.g., \"and\", \"or\")\n",
    "- CCONJ: Coordinating conjunction (same as CONJ)\n",
    "- DET: Determiner (e.g., \"the\", \"a\", \"this\")\n",
    "- INTJ: Interjection (e.g., \"oh\", \"wow\")\n",
    "- NOUN: Noun (e.g., \"cat\", \"book\")\n",
    "- NUM: Numeral (e.g., \"one\", \"2023\")\n",
    "- PART: Particle (e.g., \"not\", \"to\" in infinitives)\n",
    "- PRON: Pronoun (e.g., \"he\", \"she\", \"it\")\n",
    "- PROPN: Proper noun (e.g., \"John\", \"London\")\n",
    "- PUNCT: Punctuation (e.g., \".\", \",\", \"!\")\n",
    "- SCONJ: Subordinating conjunction (e.g., \"if\", \"because\")\n",
    "- SYM: Symbol (e.g., \"$\", \"%\")\n",
    "- VERB: Verb (e.g., \"run\", \"eat\")\n",
    "- X: Other (e.g., foreign words, abbreviations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Grained POS Tags\n",
    "\n",
    "These tags provide more detailed information about the word's role in the sentence. They are specific to English and are based on the Penn Treebank tag set. Here are some common examples:\n",
    "\n",
    "- **Adjectives (ADJ):**\n",
    "  - JJ: Adjective (e.g., \"happy\")\n",
    "  - JJR: Comparative adjective (e.g., \"happier\")\n",
    "  - JJS: Superlative adjective (e.g., \"happiest\")\n",
    "\n",
    "- **Nouns (NOUN):**\n",
    "  - NN: Singular noun (e.g., \"cat\")\n",
    "  - NNS: Plural noun (e.g., \"cats\")\n",
    "  - NNP: Singular proper noun (e.g., \"John\")\n",
    "  - NNPS: Plural proper noun (e.g., \"Vikings\")\n",
    "\n",
    "- **Verbs (VERB):**\n",
    "  - VB: Base form (e.g., \"run\")\n",
    "  - VBD: Past tense (e.g., \"ran\")\n",
    "  - VBG: Gerund/present participle (e.g., \"running\")\n",
    "  - VBN: Past participle (e.g., \"eaten\")\n",
    "  - VBP: Present tense, not 3rd person singular (e.g., \"run\")\n",
    "  - VBZ: Present tense, 3rd person singular (e.g., \"runs\")\n",
    "\n",
    "- **Adverbs (ADV):**\n",
    "  - RB: Adverb (e.g., \"quickly\")\n",
    "  - RBR: Comparative adverb (e.g., \"faster\")\n",
    "  - RBS: Superlative adverb (e.g., \"fastest\")\n",
    "\n",
    "- **Pronouns (PRON):**\n",
    "  - PRP: Personal pronoun (e.g., \"I\", \"you\")\n",
    "  - PRP$: Possessive pronoun (e.g., \"my\", \"your\")\n",
    "\n",
    "- **Determiners (DET):**\n",
    "  - DT: Determiner (e.g., \"the\", \"a\")\n",
    "  - WDT: Wh-determiner (e.g., \"which\", \"what\")\n",
    "\n",
    "- **Particles (PART):**\n",
    "  - RP: Particle (e.g., \"up\" in \"give up\")\n",
    "  - TO: Infinitive marker (e.g., \"to\" in \"to run\")\n",
    "\n",
    "- **Conjunctions (CONJ/CCONJ/SCONJ):**\n",
    "  - CC: Coordinating conjunction (e.g., \"and\", \"or\")\n",
    "  - IN: Preposition/subordinating conjunction (e.g., \"in\", \"because\")\n",
    "\n",
    "- **Punctuation (PUNCT):**\n",
    "  - .: Period\n",
    "  - ,: Comma\n",
    "  - -: Hyphen\n",
    "  - ': Apostrophe\n",
    "\n",
    "- **Other (X):**\n",
    "  - FW: Foreign word (e.g., \"bonjour\")\n",
    "  - LS: List item marker (e.g., \"1.\", \"a.\")\n",
    "  - UH: Interjection (e.g., \"uh\", \"oh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PostId</th>\n",
       "      <th>Combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74414837</td>\n",
       "      <td>We hope everyone has a safe and Happy Hallowee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74420801</td>\n",
       "      <td>Oconee County has the best Elections staff and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74420802</td>\n",
       "      <td>ðŸ‡ºðŸ‡¸Keep on voting Young CountyðŸ‡ºðŸ‡¸ Letâ€™s try and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74420805</td>\n",
       "      <td>Early Voting turnout for Monday, October 31, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74411274</td>\n",
       "      <td>Happy Halloween from the Clerk-Recorders Office!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PostId                                      Combined_text\n",
       "0  74414837  We hope everyone has a safe and Happy Hallowee...\n",
       "1  74420801  Oconee County has the best Elections staff and...\n",
       "2  74420802  ðŸ‡ºðŸ‡¸Keep on voting Young CountyðŸ‡ºðŸ‡¸ Letâ€™s try and ...\n",
       "3  74420805  Early Voting turnout for Monday, October 31, 2...\n",
       "4  74411274  Happy Halloween from the Clerk-Recorders Office! "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "df = pd.read_csv(\"../data/clean/pos_tagging_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spacy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: SpaCy, POS: PROPN, Tag: NNP\n",
      "Token: is, POS: AUX, Tag: VBZ\n",
      "Token: a, POS: DET, Tag: DT\n",
      "Token: powerful, POS: ADJ, Tag: JJ\n",
      "Token: library, POS: NOUN, Tag: NN\n",
      "Token: for, POS: ADP, Tag: IN\n",
      "Token: natural, POS: ADJ, Tag: JJ\n",
      "Token: language, POS: NOUN, Tag: NN\n",
      "Token: processing, POS: NOUN, Tag: NN\n",
      "Token: ., POS: PUNCT, Tag: .\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Sample text\n",
    "text = \"SpaCy is a powerful library for natural language processing.\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Iterate over the tokens and print their POS tags\n",
    "for token in doc:\n",
    "    print(f\"Token: {token.text}, POS: {token.pos_}, Tag: {token.tag_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counts of word types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS: DET\n",
      "  the: 8\n",
      "POS: ADJ\n",
      "  ambitious: 1\n",
      "  emotional: 1\n",
      "  confident: 1\n",
      "  supportive: 1\n",
      "  aggressive: 1\n",
      "  polite: 1\n",
      "  same: 1\n",
      "POS: NOUN\n",
      "  man: 1\n",
      "  woman: 1\n",
      "  leader: 1\n",
      "  assistant: 1\n",
      "  plan: 1\n",
      "  boy: 1\n",
      "  girl: 1\n",
      "  class: 1\n",
      "POS: CCONJ\n",
      "  and: 3\n",
      "POS: VERB\n",
      "  worked: 1\n",
      "  presented: 1\n",
      "POS: ADV\n",
      "  together: 1\n",
      "POS: PUNCT\n",
      "  .: 3\n",
      "POS: AUX\n",
      "  were: 1\n",
      "POS: ADP\n",
      "  in: 1\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load the SpaCy model\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"The ambitious man and the emotional woman worked together.\",\n",
    "    \"The confident leader and the supportive assistant presented the plan.\",\n",
    "    \"The aggressive boy and the polite girl were in the same class.\"\n",
    "]\n",
    "\n",
    "# Initialize a dictionary to store word counts by POS\n",
    "pos_counts = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# Process each document\n",
    "for doc_text in documents:\n",
    "    doc = nlp(doc_text)\n",
    "    for token in doc:\n",
    "        pos_counts[token.pos_][token.text.lower()] += 1\n",
    "\n",
    "# Print the results\n",
    "for pos, words in pos_counts.items():\n",
    "    print(f\"POS: {pos}\")\n",
    "    for word, count in words.items():\n",
    "        print(f\"  {word}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dependency parsing or collocation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjective-Noun Pairs:\n"
     ]
    }
   ],
   "source": [
    "# Extract adjective-noun pairs\n",
    "adj_noun_pairs = []\n",
    "\n",
    "for doc_text in documents:\n",
    "    doc = nlp(doc_text)\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"ADJ\":\n",
    "            for child in token.children:\n",
    "                if child.pos_ == \"NOUN\":\n",
    "                    adj_noun_pairs.append((token.text.lower(), child.text.lower()))\n",
    "\n",
    "# Print the results\n",
    "print(\"Adjective-Noun Pairs:\")\n",
    "for adj, noun in adj_noun_pairs:\n",
    "    print(f\"  {adj} {noun}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment on pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Analyze sentiment of adjectives\n",
    "for adj, noun in adj_noun_pairs:\n",
    "    blob = TextBlob(f\"{adj} {noun}\")\n",
    "    sentiment = blob.sentiment.polarity  # Range: -1 (negative) to 1 (positive)\n",
    "    print(f\"Pair: {adj} {noun}, Sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broad Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Prepare the documents\n",
    "texts = [doc.text for doc in nlp.pipe(documents)]\n",
    "\n",
    "# Create a document-term matrix\n",
    "vectorizer = CountVectorizer(stop_words=\"english\")\n",
    "dtm = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Perform topic modeling\n",
    "lda = LatentDirichletAllocation(n_components=2, random_state=42)\n",
    "lda.fit(dtm)\n",
    "\n",
    "# Print the top words for each topic\n",
    "for idx, topic in enumerate(lda.components_):\n",
    "    print(f\"Topic {idx}:\")\n",
    "    print([vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-5:]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdi_tone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
