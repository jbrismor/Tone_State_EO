{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS tagging lists\n",
    "\n",
    "This notebook is used to create the lists of words for further bias identification using the POS tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/clean/clean_posts_for_POS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PostId</th>\n",
       "      <th>POS_tagging_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80074859</td>\n",
       "      <td>While in Camden today I had the privilege to v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80069324</td>\n",
       "      <td>I had a great visit this afternoon with the Wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80072838</td>\n",
       "      <td>On November 29, the State Canvassing Board cer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80076411</td>\n",
       "      <td>The State Canvassing Board certified the 2022 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80107630</td>\n",
       "      <td>: To all Baltimore County Election Judges who ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PostId                                   POS_tagging_text\n",
       "0  80074859  While in Camden today I had the privilege to v...\n",
       "1  80069324  I had a great visit this afternoon with the Wi...\n",
       "2  80072838  On November 29, the State Canvassing Board cer...\n",
       "3  80076411  The State Canvassing Board certified the 2022 ...\n",
       "4  80107630  : To all Baltimore County Election Judges who ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22311"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PostId              0\n",
       "POS_tagging_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count NaN values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbm/miniforge3/envs/mdi_tone/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Adjective_counts.csv with 2028 unique words\n",
      "Created Noun_counts.csv with 11106 unique words\n",
      "Created Auxiliary_Verb_counts.csv with 58 unique words\n",
      "Created Verb_counts.csv with 4079 unique words\n",
      "Created Adverb_counts.csv with 620 unique words\n",
      "Created Pronoun_counts.csv with 112 unique words\n",
      "Created Other_counts.csv with 142 unique words\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_trf\", disable=[\"ner\", \"parser\"]) # en_core_web_trf en_core_web_lg\n",
    "\n",
    "# Enhanced POS categorization\n",
    "def extract_pos(doc):\n",
    "    nouns = []\n",
    "    adjectives = []\n",
    "    aux_verbs = []\n",
    "    verbs = []\n",
    "    adverbs = []\n",
    "    pronouns = []\n",
    "    other = []  # For interjections (INTJ) and other non-specified categories\n",
    "    \n",
    "    for token in doc:\n",
    "        word = token.text.lower()\n",
    "        pos = token.pos_\n",
    "        \n",
    "        if pos in [\"NOUN\", \"PROPN\"]:\n",
    "            nouns.append(word)\n",
    "        elif pos == \"ADJ\":\n",
    "            adjectives.append(word)\n",
    "        elif pos == \"AUX\":\n",
    "            aux_verbs.append(word)\n",
    "        elif pos == \"VERB\":\n",
    "            verbs.append(word)\n",
    "        elif pos == \"ADV\":\n",
    "            adverbs.append(word)\n",
    "        elif pos == \"PRON\":\n",
    "            pronouns.append(word)\n",
    "        elif pos == \"INTJ\":  # Interjections\n",
    "            other.append(word)\n",
    "    \n",
    "    return nouns, adjectives, aux_verbs, verbs, adverbs, pronouns, other\n",
    "\n",
    "# Process texts and store results\n",
    "df['pos_results'] = df['POS_tagging_text'].apply(lambda x: extract_pos(nlp(x)))\n",
    "\n",
    "# Split into separate columns\n",
    "pos_columns = ['nouns', 'adjectives', 'aux_verbs', 'verbs', 'adverbs', 'pronouns', 'other']\n",
    "df[pos_columns] = pd.DataFrame(df['pos_results'].tolist(), index=df.index)\n",
    "\n",
    "# Generate CSVs for each category\n",
    "category_mapping = {\n",
    "    'adjectives': 'Adjective',\n",
    "    'nouns': 'Noun',\n",
    "    'aux_verbs': 'Auxiliary_Verb',\n",
    "    'verbs': 'Verb',\n",
    "    'adverbs': 'Adverb',\n",
    "    'pronouns': 'Pronoun',\n",
    "    'other': 'Other'\n",
    "}\n",
    "\n",
    "for df_col, category in category_mapping.items():\n",
    "    # Flatten all words in the category\n",
    "    all_words = [word for sublist in df[df_col] for word in sublist]\n",
    "    \n",
    "    # Count occurrences\n",
    "    word_counts = Counter(all_words)\n",
    "    \n",
    "    # Create DataFrame and save\n",
    "    count_df = pd.DataFrame({\n",
    "        'word': list(word_counts.keys()),\n",
    "        'count': list(word_counts.values())\n",
    "    }).sort_values('count', ascending=False)\n",
    "    \n",
    "    count_df.to_csv(f\"{category}_counts.csv\", index=False)\n",
    "    print(f\"Created {category}_counts.csv with {len(count_df)} unique words\")\n",
    "\n",
    "# Optional: Clean up intermediate columns\n",
    "df.drop(columns=['pos_results'], inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdi_tone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
